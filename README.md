# ğŸš€ Credit Risk Scoring AI | ä¿¡ç”¨è¯„åˆ† AI

## ğŸ“Œ Project Overview | é¡¹ç›®ç®€ä»‹
This project aims to build a **Credit Risk Scoring Model** to predict user default risk.

- **Data Handling**: Use SQL to extract, clean, and process data.
- **Model Comparison**: Train and evaluate **Logistic Regression, XGBoost, LightGBM**.
- **Visualization**: Analyze data distribution, feature importance, and model performance.
- **GitHub Representation**: Include SQL queries, feature engineering, and Jupyter Notebook examples.

æœ¬é¡¹ç›®æ—¨åœ¨æ„å»ºä¸€ä¸ª **ä¿¡ç”¨è¯„åˆ†æ¨¡å‹**ï¼Œç”¨äºé¢„æµ‹ç”¨æˆ·çš„è¿çº¦é£é™©ã€‚

- **æ•°æ®è·å–ä¸å­˜å‚¨**ï¼šä½¿ç”¨ SQL æå–ã€æ¸…ç†å¹¶å¤„ç†æ•°æ®ã€‚
- **æ¨¡å‹å¯¹æ¯”**ï¼šä½¿ç”¨ **Logistic Regression, XGBoost, LightGBM** è¿›è¡Œè®­ç»ƒã€‚
- **å¯è§†åŒ–**ï¼šåˆ†ææ•°æ®åˆ†å¸ƒã€ç‰¹å¾é‡è¦æ€§ï¼Œå¹¶å±•ç¤ºæ¨¡å‹å¯¹æ¯”ç»“æœã€‚
- **GitHub ä½“ç°**ï¼šæä¾› SQL æŸ¥è¯¢ã€ç‰¹å¾å·¥ç¨‹ã€è®­ç»ƒä»£ç ï¼Œå¹¶åŒ…å« Jupyter Notebook ç¤ºä¾‹ã€‚

---

## ğŸ“‚ Directory Structure | ç›®å½•ç»“æ„
```
credit-risk-scoring/
â”‚â”€â”€ data/                     # Data storage (local) | æ•°æ®å­˜æ”¾ï¼ˆæœ¬åœ°ï¼‰
â”‚   â”œâ”€â”€ raw_data.csv          # Raw CSV data | åŸå§‹ CSV æ•°æ®
â”‚   â”œâ”€â”€ processed_data.csv     # Processed data | é¢„å¤„ç†åçš„æ•°æ®
â”‚
â”‚â”€â”€ notebooks/                 # Jupyter Notebooks
â”‚   â”œâ”€â”€ EDA.ipynb              # Data Exploration & Visualization | æ•°æ®æ¢ç´¢ & å¯è§†åŒ–
â”‚   â”œâ”€â”€ Feature_Engineering.ipynb # Feature Engineering & SQL Processing | ç‰¹å¾å·¥ç¨‹ & SQL å¤„ç†
â”‚   â”œâ”€â”€ Model_Comparison.ipynb # Model Comparison | æœºå™¨å­¦ä¹ æ¨¡å‹å¯¹æ¯”
â”‚
â”‚â”€â”€ sql/                      # SQL Scripts | SQL è„šæœ¬
â”‚   â”œâ”€â”€ data_extraction.sql    # Data Extraction SQL | æ•°æ®æå– SQL è¯­å¥
â”‚   â”œâ”€â”€ data_cleaning.sql      # Data Cleaning SQL | æ•°æ®æ¸…æ´— SQL è¯­å¥
â”‚
â”‚â”€â”€ src/                      # Python Scripts | Python ä»£ç 
â”‚   â”œâ”€â”€ data_loader.py        # SQL Data Loader | è¯»å– SQL æ•°æ®
â”‚   â”œâ”€â”€ feature_engineering.py # Feature Engineering | ç‰¹å¾å·¥ç¨‹
â”‚   â”œâ”€â”€ model_training.py      # Model Training | è®­ç»ƒå¤šä¸ªæ¨¡å‹
â”‚   â”œâ”€â”€ visualization.py       # Results Visualization | ç»“æœå¯è§†åŒ–
â”‚
â”‚â”€â”€ results/                   # Results Storage | ç»“æœå­˜æ”¾
â”‚   â”œâ”€â”€ model_performance.png  # Model Performance Visualization | æ¨¡å‹å¯¹æ¯”å›¾
â”‚
â”‚â”€â”€ README.md                  # Project Documentation | é¡¹ç›®è¯´æ˜
â”‚â”€â”€ requirements.txt           # Dependencies | ä¾èµ–åŒ…
â”‚â”€â”€ LICENSE                    # Open Source License | å¼€æºè®¸å¯
```

---

## ğŸ”§ Project Steps | é¡¹ç›®æ­¥éª¤
This project follows these key steps:

æœ¬é¡¹ç›®æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤è¿›è¡Œï¼š

### **1ï¸âƒ£ Data Extraction & Storage | æ•°æ®è·å–ä¸å­˜å‚¨**
- Select an appropriate dataset, such as **Kaggle Home Credit Default Risk**.
- Use SQL to extract, clean, and store the data.
- Read database data using Pandas for basic exploration.

- é€‰æ‹©åˆé€‚çš„æ•°æ®é›†ï¼Œå¦‚ **Kaggle Home Credit Default Risk**ã€‚
- ä½¿ç”¨ SQL è¿›è¡Œæ•°æ®æå–ã€æ¸…ç†ï¼Œå¹¶å­˜å…¥æ•°æ®åº“ã€‚
- é€šè¿‡ Pandas è¯»å–æ•°æ®åº“æ•°æ®ï¼Œè¿›è¡ŒåŸºæœ¬æ•°æ®æ¢ç´¢ã€‚

### **2ï¸âƒ£ Exploratory Data Analysis (EDA) | æ•°æ®æ¢ç´¢**
- Analyze statistical characteristics such as credit score distribution.
- Handle missing values and outliers.
- Visualize feature relationships using correlation matrices.

- ç»Ÿè®¡æ•°æ®ç‰¹å¾ï¼Œå¦‚ä¿¡ç”¨è¯„åˆ†åˆ†å¸ƒã€æ”¶å…¥æƒ…å†µç­‰ã€‚
- å¤„ç†ç¼ºå¤±å€¼ã€å¼‚å¸¸å€¼ï¼Œç¡®ä¿æ•°æ®è´¨é‡ã€‚
- ç»˜åˆ¶ç›¸å…³æ€§çŸ©é˜µï¼Œåˆ†æç‰¹å¾é—´çš„å…³ç³»ã€‚

### **3ï¸âƒ£ Feature Engineering | ç‰¹å¾å·¥ç¨‹**
- Create new credit risk features such as **income-to-loan ratio, age groups**.
- Perform feature scaling and categorical encoding.
- Generate features using SQL + Pandas.

- åˆ›å»ºæ–°çš„ä¿¡ç”¨é£é™©ç‰¹å¾ï¼Œå¦‚ **æ”¶å…¥/è´·æ¬¾æ¯”ç‡ã€å¹´é¾„åˆ†ç»„ç­‰**ã€‚
- è¿›è¡Œç‰¹å¾ç¼©æ”¾ã€ç±»åˆ«å˜é‡å¤„ç†ï¼Œæé«˜æ¨¡å‹æ³›åŒ–èƒ½åŠ›ã€‚
- ä½¿ç”¨ SQL + Pandas è¿›è¡Œç‰¹å¾ç”Ÿæˆã€‚

### **4ï¸âƒ£ Model Training | æœºå™¨å­¦ä¹ æ¨¡å‹è®­ç»ƒ**
- Train **Logistic Regression, XGBoost, LightGBM** models.
- Use cross-validation to ensure model robustness.
- Compute key metrics such as AUC and accuracy.

- é€‰æ‹© **Logistic Regressionã€XGBoostã€LightGBM** è¿›è¡Œå»ºæ¨¡ã€‚
- é‡‡ç”¨äº¤å‰éªŒè¯æ–¹å¼ï¼Œç¡®ä¿æ¨¡å‹ç¨³å¥æ€§ã€‚
- è®¡ç®— AUCã€å‡†ç¡®ç‡ç­‰å…³é”®æŒ‡æ ‡ï¼Œè¯„ä¼°æ¨¡å‹æ•ˆæœã€‚

### **5ï¸âƒ£ Model Evaluation & Visualization | ç»“æœå¯è§†åŒ–**
- Plot data distributions, such as credit score histograms.
- Generate model performance comparison charts.
- Use SHAP analysis to interpret key features.

- ç»˜åˆ¶æ•°æ®åˆ†å¸ƒå›¾ï¼Œå¦‚ä¿¡ç”¨è¯„åˆ†ç›´æ–¹å›¾ã€‚
- ç”Ÿæˆæ¨¡å‹è¡¨ç°å¯¹æ¯”å›¾ï¼Œå±•ç¤º AUCã€å‡†ç¡®ç‡ã€‚
- é€šè¿‡ SHAP è§£é‡Šæ¨¡å‹ï¼Œåˆ†æé‡è¦ç‰¹å¾ã€‚

### **6ï¸âƒ£ Running & Deployment | è¿è¡Œä¸éƒ¨ç½²**
- Install dependencies from `requirements.txt`.
- Run SQL scripts to prepare the database.
- Execute the model training script to generate predictions.

- é€šè¿‡ `requirements.txt` å®‰è£…ä¾èµ–ã€‚
- è¿è¡Œ SQL è„šæœ¬ï¼Œå‡†å¤‡æ•°æ®åº“ã€‚
- è¿è¡Œæ¨¡å‹è®­ç»ƒè„šæœ¬ï¼Œç”Ÿæˆä¿¡ç”¨è¯„åˆ†é¢„æµ‹ã€‚

---

## ğŸš€ How to Run | å¦‚ä½•è¿è¡Œæœ¬é¡¹ç›®ï¼Ÿ
### **1ï¸âƒ£ Install Dependencies | å®‰è£…ä¾èµ–**
```sh
pip install -r requirements.txt
```

### **2ï¸âƒ£ Run SQL Scripts & Load Data | è¿è¡Œ SQL è„šæœ¬ & åŠ è½½æ•°æ®**
```sh
sqlite3 database.db < sql/data_extraction.sql
```

### **3ï¸âƒ£ Train Models | è®­ç»ƒæ¨¡å‹**
```sh
python src/model_training.py
```

### **4ï¸âƒ£ Generate Visualization Results | ç”Ÿæˆå¯è§†åŒ–ç»“æœ**
```sh
python src/visualization.py
```

---

## ğŸ“œ License | è®¸å¯è¯
This project is open-source under the **MIT License**. Contributions are welcome!

æœ¬é¡¹ç›®åŸºäº **MIT License** å¼€æºã€‚æ¬¢è¿è´¡çŒ®å’Œæ”¹è¿›ï¼

